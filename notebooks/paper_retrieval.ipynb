{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing_extensions import TypedDict, List\n",
    "\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain_core.documents import Document\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import (\n",
    "    query_transformation_prompt,\n",
    "    llm_prompt,\n",
    ")\n",
    "\n",
    "from configs import (\n",
    "    QDRANT_URL,\n",
    "    QDRANT_API_KEY,\n",
    "    OLLAMA_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d25e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chat(TypedDict):\n",
    "    user_query: str\n",
    "    transformed_query: str\n",
    "    metadata: List[dict]\n",
    "    summaries: List[str]\n",
    "    similarity_scores: List[float]\n",
    "    answer: str\n",
    "    token_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48363df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embeddings  = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=dense_embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=True,\n",
    "    collection_name=\"axRiv_research_papers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"mistral\",\n",
    "    base_url=OLLAMA_URL,\n",
    "    temperature=0.0,\n",
    "    num_predict=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_transformation(state: chat) -> dict:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", query_transformation_prompt),\n",
    "        (\"human\", \"{query}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"query\": state[\"user_query\"]})\n",
    "    return {\"transformed_query\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(state: chat) -> dict:\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        state[\"transformed_query\"], k=5\n",
    "    )\n",
    "\n",
    "    metadata_list, summaries, scores = [], [], []\n",
    "    for doc, score in results:\n",
    "        metadata_list.append(doc.metadata)\n",
    "        summaries.append(doc.page_content)\n",
    "        scores.append(score)\n",
    "\n",
    "    return {\n",
    "        \"metadata\": metadata_list,\n",
    "        \"summaries\": summaries,\n",
    "        \"similarity_scores\": scores,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: chat) -> dict:\n",
    "    papers_block = \"\\n\\n\".join(\n",
    "        f\"• **{md.get('Title', 'No title')}** ({md.get('url', 'No URL')})\\n  {summ}\"\n",
    "        for md, summ in zip(state[\"metadata\"], state[\"summaries\"])\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", llm_prompt),\n",
    "        (\"human\", \"{query}\\n{context}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"query\":   state[\"user_query\"],\n",
    "        \"context\": papers_block\n",
    "    })\n",
    "\n",
    "    if response is None:\n",
    "        raise RuntimeError(\"LLM invocation returned None—check your LLM client or network settings.\")\n",
    "\n",
    "    usage_meta = getattr(response, \"usage_metadata\", {}) or {}\n",
    "    token_count = usage_meta.get(\"total_tokens\", 0)\n",
    "\n",
    "    return {\"answer\": response.content, \"token_count\": token_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_builder = StateGraph(chat)\n",
    "chat_builder.add_node(\"query_transformation\", query_transformation)\n",
    "chat_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "chat_builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "chat_builder.add_edge(START, \"query_transformation\")\n",
    "chat_builder.add_edge(\"query_transformation\", \"retrieve_documents\")\n",
    "chat_builder.add_edge(\"retrieve_documents\", \"generate_answer\")\n",
    "chat_builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "chat_llm = chat_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    init_state: chat = {\n",
    "        \"user_query\": \"What is Reinforcement Learning?\",\n",
    "        \"transformed_query\": \"\",\n",
    "        \"metadata\": [], \"summaries\": [], \"similarity_scores\": [],\n",
    "        \"answer\": \"\", \"token_count\": 0\n",
    "    }\n",
    "    result = chat_llm.invoke(init_state)\n",
    "    print(\"=== ANSWER ===\")\n",
    "    print(result[\"answer\"])\n",
    "    print(\"\\n=== Similarity Scores ===\")\n",
    "    print(result[\"similarity_scores\"])\n",
    "\n",
    "    print(\"\\n=== Top 5 Paper Metadata ===\")\n",
    "    for i, md in enumerate(result[\"metadata\"], start=1):\n",
    "        print(f\"\\nPaper {i}:\")\n",
    "        print(json.dumps(md, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
