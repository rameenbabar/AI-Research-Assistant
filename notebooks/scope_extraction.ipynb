{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from typing_extensions import TypedDict, List\n",
    "\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain_core.documents import Document\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from scope_prompt import query_transformation_prompt, scope_prompt\n",
    "from configs import QDRANT_URL, QDRANT_API_KEY, OLLAMA_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322552d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    user_query: str\n",
    "    transformed_query: str\n",
    "    metadata: List[dict]\n",
    "    summaries: List[str]\n",
    "    similarity_scores: List[float]\n",
    "    scope: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade88bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = PromptTemplate.from_template(query_transformation_prompt)\n",
    "scope_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=scope_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d31020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(state: ChatState) -> dict:\n",
    "    hits = vector_store.similarity_search_with_score(\n",
    "        state[\"transformed_query\"], k=5\n",
    "    )\n",
    "    metas, texts, scores = [], [], []\n",
    "    for doc, score in hits:\n",
    "        metas.append(doc.metadata)\n",
    "        texts.append(doc.page_content)\n",
    "        scores.append(score)\n",
    "    return {\n",
    "        \"metadata\": metas,\n",
    "        \"summaries\": texts,\n",
    "        \"similarity_scores\": scores,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab62ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scope(state: ChatState) -> dict:\n",
    "    context_text = \"\\n\\n\".join(state[\"summaries\"])\n",
    "    filled_prompt = scope_template.format(context=context_text)\n",
    "    print(\"=== Filled scope prompt ===\")\n",
    "    print(filled_prompt)\n",
    "\n",
    "    resp = llm.invoke(filled_prompt)\n",
    "    output = resp.content.strip()\n",
    "\n",
    "    try:\n",
    "        parsed = ast.literal_eval(output)\n",
    "        if isinstance(parsed, (dict, list)):\n",
    "            return {\"scope\": json.dumps(parsed, indent=2)}\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\"scope\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_builder = StateGraph(ChatState)\n",
    "chat_builder.add_node(\"query_transformation\", query_transformation)\n",
    "chat_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "chat_builder.add_node(\"extract_scope\", extract_scope)\n",
    "\n",
    "chat_builder.add_edge(START, \"query_transformation\")\n",
    "chat_builder.add_edge(\"query_transformation\", \"retrieve_documents\")\n",
    "chat_builder.add_edge(\"retrieve_documents\", \"extract_scope\")\n",
    "chat_builder.add_edge(\"extract_scope\", END)\n",
    "\n",
    "chat_pipeline = chat_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    init: ChatState = {\n",
    "        \"user_query\": \"Based on the limitations in this paper, what future research gaps can you identify?\",\n",
    "        \"transformed_query\": \"\",\n",
    "        \"metadata\": [],\n",
    "        \"summaries\": [],\n",
    "        \"similarity_scores\": [],\n",
    "        \"scope\": \"\",\n",
    "    }\n",
    "\n",
    "    result = chat_pipeline.invoke(init)\n",
    "\n",
    "    print(\"\\n=== Paper Scope ===\")\n",
    "    print(result[\"scope\"])\n",
    "    print(\"\\n=== Similarity Scores ===\")\n",
    "    print(result[\"similarity_scores\"])\n",
    "    print(\"\\n=== Top Document Metadata ===\")\n",
    "    print(json.dumps(result[\"metadata\"][0], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
