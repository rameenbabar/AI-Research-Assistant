{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389e056",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "from moviepy import VideoFileClip, AudioFileClip\n",
    "from gtts import gTTS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38598e7b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral\", temperature=0.7)\n",
    "\n",
    "dense_embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a19f5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    documents=[],\n",
    "    embedding=dense_embedder,\n",
    "    url=\"\",\n",
    "    api_key=\"\",\n",
    "    prefer_grpc=True,\n",
    "    collection_name=\"axRiv_research_papers\", #collection name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145bf4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "explanation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an expert narrator who transforms formal academic research summaries into clear, engaging, and listener-friendly spoken scripts. \"\n",
    "     \"Your narration should sound natural, conversational, and engaging â€” like explaining the key ideas to an intelligent but non-expert audience. \"\n",
    "     \"Avoid heavy jargon unless necessary, and if used, briefly explain it in simple terms. \"\n",
    "     \"Maintain accuracy while improving flow and clarity. \"\n",
    "     \"Use transitions, emphasis, and storytelling techniques to keep the listener interested.\"\n",
    "    ),\n",
    "    (\"user\", \n",
    "     \"Here is a research summary:\\n\\n{summary}\\n\\n\"\n",
    "     \"Please rewrite this as a spoken-friendly narration, keeping it clear, concise, and engaging for a general audience.\"\n",
    "    )\n",
    "])\n",
    "explanation_chain = explanation_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69768c88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def narrate_summary(summary: str) -> str:\n",
    "    response = explanation_chain.invoke({\"summary\": summary})\n",
    "    return response.content if hasattr(response, \"content\") else response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d35716",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_summary_by_title(title_query: str) -> str:\n",
    "    docs = qdrant.similarity_search(title_query, k=20)\n",
    "    for doc in docs:\n",
    "        if title_query.lower() in doc.metadata.get(\"Title\", \"\").lower():\n",
    "            return doc.page_content\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec7940",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pdf_title_map = {\n",
    "    \"A Formal Measure of Machine Intelligence\": \"p1.pdf\",\n",
    "    \"Creativity and Artificial Intelligence: A Digital Art Perspective\": \"p2.pdf\",\n",
    "    \"Introduction to intelligent computing unit 1\": \"p3.pdf\",\n",
    "    \"The Next Decade in AI:Four Steps Towards Robust Artificial Intelligence\": \"p4.pdf\",\n",
    "    \"Perspective: Purposeful Failure in Artificial Life and Artificial Intelligence\": \"p5.pdf\",\n",
    "    \"Machine Learning in Artificial Intelligence: Towards a Common Understanding\": \"p6.pdf\",\n",
    "    \"Human in the AI loop via xAI and Active Learning for Visual Inspection\": \"p7.pdf\",\n",
    "    \"Comprehensible Artificial Intelligence on Knowledge Graphs: A Survey.\": \"p8.pdf\",\n",
    "    \"Watershed for Artificial Intelligence: Human Intelligence, Machine Intelligence, and Biological Intelligence\": \"p9.pdf\",\n",
    "    \"Machine learning and deep learning\": \"p10.pdf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee07682",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_video_for_paper(paper_title: str, papers_folder=\"papers\"):\n",
    "    summary = fetch_summary_by_title(paper_title)\n",
    "    if not summary:\n",
    "        return None, \"Paper not found in vector database.\"\n",
    "\n",
    "    natural_explanation = narrate_summary(summary)\n",
    "    tts = gTTS(natural_explanation)\n",
    "    tts.save(\"narration.mp3\")\n",
    "    audio_path = \"narration.mp3\"\n",
    "\n",
    "    pdf_filename = pdf_title_map.get(paper_title)\n",
    "    if not pdf_filename:\n",
    "        return None, \"PDF not found for this title.\"\n",
    "    pdf_path = os.path.join(papers_folder, pdf_filename)\n",
    "\n",
    "    image_folder = \"pdf_frames\"\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_files = []\n",
    "    for i, page in enumerate(doc):\n",
    "        pix = page.get_pixmap(dpi=150)\n",
    "        img_path = os.path.join(image_folder, f\"page_{i+1}.png\")\n",
    "        pix.save(img_path)\n",
    "        image_files.append(img_path)\n",
    "    doc.close()\n",
    "\n",
    "    from moviepy import AudioFileClip\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    total_audio_duration = audio_clip.duration\n",
    "    seconds_per_page = total_audio_duration / len(image_files)\n",
    "    fps = 1  # keep 1 FPS so timing is simple\n",
    "\n",
    "    pix = fitz.open(pdf_path)[0].get_pixmap(dpi=150)\n",
    "    frame_size = (pix.width, pix.height)\n",
    "    video_path = \"video_no_audio.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, fps, frame_size)\n",
    "\n",
    "    frames_to_repeat = int(seconds_per_page * fps)\n",
    "    for img_path in image_files:\n",
    "        frame = cv2.imread(img_path)\n",
    "        for _ in range(frames_to_repeat):\n",
    "            video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "\n",
    "    from moviepy import VideoFileClip\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    final_clip = video_clip.with_audio(audio_clip)\n",
    "    output_path = \"final_video.mp4\"\n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    return output_path, None\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
