{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing_extensions import TypedDict, List\n",
    "import ast\n",
    "import re, json, ast\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain_core.documents import Document\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_prompt import (\n",
    "    query_transformation_prompt,\n",
    "    dataset_prompt \n",
    ")\n",
    "\n",
    "from configs import (\n",
    "    QDRANT_URL,\n",
    "    QDRANT_API_KEY,\n",
    "    OLLAMA_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611420e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chat(TypedDict):\n",
    "    user_query: str\n",
    "    transformed_query: str\n",
    "    metadata: List[dict]\n",
    "    summaries: List[str]\n",
    "    similarity_scores: List[float]\n",
    "    datasets: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ef035",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=dense_embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=True,\n",
    "    collection_name=\"The Next Decade in AI Four Steps Towards Robust Artificial Intelligence\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ddcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"mistral\",\n",
    "    base_url=OLLAMA_URL,\n",
    "    temperature=0.0,\n",
    "    num_predict=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_transformation(state: chat) -> dict:\n",
    "    prompt = PromptTemplate.from_template(query_transformation_prompt)\n",
    "    formatted_prompt = prompt.format(query=state[\"user_query\"])\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    return {\"transformed_query\": response.content.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(state: chat) -> dict:\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        state[\"transformed_query\"], k=5\n",
    "    )\n",
    "\n",
    "    metadata_list, summaries, scores = [], [], []\n",
    "    for doc, score in results:\n",
    "        metadata_list.append(doc.metadata)\n",
    "        summaries.append(doc.page_content)\n",
    "        scores.append(score)\n",
    "\n",
    "    return {\n",
    "        \"metadata\": metadata_list,\n",
    "        \"summaries\": summaries,\n",
    "        \"similarity_scores\": scores,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63be265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datasets(state: chat) -> dict:\n",
    "    paper_content = \"\\n\\n\".join(state[\"summaries\"])\n",
    "\n",
    "    prompt = PromptTemplate.from_template(dataset_prompt)\n",
    "    formatted_prompt = prompt.format(context=paper_content)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    raw_output = response.content.strip()\n",
    "\n",
    "    print(\"\\nRaw LLM Output:\\n\", raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_builder = StateGraph(chat)\n",
    "chat_builder.add_node(\"query_transformation\", query_transformation)\n",
    "chat_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "chat_builder.add_node(\"extract_datasets\", extract_datasets)\n",
    "\n",
    "chat_builder.add_edge(START, \"query_transformation\")\n",
    "chat_builder.add_edge(\"query_transformation\", \"retrieve_documents\")\n",
    "chat_builder.add_edge(\"retrieve_documents\", \"extract_datasets\")\n",
    "chat_builder.add_edge(\"extract_datasets\", END)\n",
    "\n",
    "chat_llm = chat_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    init_state: chat = {\n",
    "        \"user_query\": \"List the datasets used in this paper, with exact names. Give output in the form of a python List and do not include sections or any other explanations. \",\n",
    "        \"transformed_query\": \"\",\n",
    "        \"metadata\": [],\n",
    "        \"summaries\": [],\n",
    "        \"similarity_scores\": [],\n",
    "        \"datasets\": \"\"\n",
    "    }\n",
    "\n",
    "    result = chat_llm.invoke(init_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
